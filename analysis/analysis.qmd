---
title: "Exploratory Data Analysis"
author: George Whittington
date: today
date-format: long
---

```{python}
#| label: libraries
#| output: false

import polars as pl
import polars.selectors as cs

import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
import great_tables

from pyhere import here

#plt.style.use("ggplot")
sns.set_style("darkgrid", {"axes.facecolor": ".9"})
sns.color_palette("crest", as_cmap=True);
```

# Source Apportionment

Source apportionment is a "collection of techniques to provide information
regarding how much a source (usually a generalized category) contributes to the
overall pollutant concentration at receptor (usually a monitoring site)"
(Rizzo, 2010).

"Source apportionment is the process of statistically estimating the relative
contributions from a set of sources to the observed sample data" (Smith, 2025).

In our case, we will use source apportionment as a method of unsupervised
learning applied to air quality data. By analyzing the chemical composition of
each observation, we will use Non-Negative/Positive Matrix Factorization
(NMF/PMF) to extract latent factors from the data. We can then interpret these
factors to identify specific source profiles (the chemical makeup of the source)
and calculate their corresponding source contributions (the amount of pollution
from that source) over time.

Statistically, this approach functions as a specialized form of Factor Analysis.
While traditional Factor Analysis allows for negative values in its mathematical
solution, our context requires a strict non-negativity constraint because
physical matter (pollution) cannot exist in negative quantities. Therefore, we
treat the unknown pollution sources as latent factors (hidden variables that
drive the observed variance in the data) and solve for them using algorithms
that enforce positive values.

# Data

```{python}
#| label: load-data

# baltimore unclean
baltimore_con_old = pl.read_csv(here("data/Dataset-Baltimore_con.csv"))
baltimore_unc_old = pl.read_csv(here("data/Dataset-Baltimore_unc.csv"))

# baltimore clean
baltimore_con = pl.read_csv(here("data/wide/baltimore_concentration.csv"))
baltimore_unc = pl.read_csv(here("data/wide/baltimore_uncertainty.csv"))
baltimore_lon = pl.read_csv(here("data/long/baltimore_long.csv"))

# baton rouge unclean
baton_rouge_con_old = pl.read_csv(here("data/Dataset-BatonRouge-con.csv"))
baton_rouge_unc_old = pl.read_csv(here("data/Dataset-BatonRouge-unc.csv"))

# baton rouge clean
baton_rouge_con = pl.read_csv(here("data/wide/baton_rouge_concentration.csv"))
baton_rouge_unc = pl.read_csv(here("data/wide/baton_rouge_uncertainty.csv"))
baton_rouge_lon = pl.read_csv(here("data/long/baton_rouge_long.csv"))

# st louis unclean 
st_louis_con_old = pl.read_csv(here("data/Dataset-StLouis-con.csv"))
st_louis_unc_old = pl.read_csv(here("data/Dataset-StLouis-unc.csv"))

# st louis clean
st_louis_con = pl.read_csv(here("data/wide/st_louis_concentration.csv"))
st_louis_unc = pl.read_csv(here("data/wide/st_louis_uncertainty.csv"))
st_louis_lon = pl.read_csv(here("data/long/st_louis_long.csv"))
```

## Head of All the Data

```{python}
#| label: tbl-head-baltimore-con-old
#| tbl-cap: Baltimore Concentration Old
#| echo: false

(
    baltimore_con_old
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baltimore-unc-old
#| tbl-cap: Baltimore Uncertainty Old
#| echo: false

(
    baltimore_unc_old
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baltimore-con
#| tbl-cap: Baltimore Concentration
#| echo: false

(
    baltimore_con
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baltimore-unc
#| tbl-cap: Baltimore Uncertainty
#| echo: false

(
    baltimore_unc
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baltimore-lon
#| tbl-cap: Baltimore Combined
#| echo: false

(
    baltimore_lon
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baton-rouge-con-old
#| tbl-cap: Baton Rouge Concentration Old
#| echo: false

(
    baton_rouge_con_old
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baton-rouge-unc-old
#| tbl-cap: Baton Rouge Uncertainty Old
#| echo: false

(
    baton_rouge_unc_old
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baton-rouge-con
#| tbl-cap: Baton Rouge Concentration
#| echo: false

(
    baton_rouge_con
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baton-rouge-unc
#| tbl-cap: Baton Rouge Uncertainty
#| echo: false

(
    baton_rouge_unc
    .head()
    .style
)
```

```{python}
#| label: tbl-head-baton-rouge-lon
#| tbl-cap: Baton Rouge Combined
#| echo: false

(
    baton_rouge_lon
    .head()
    .style
)
```

```{python}
#| label: tbl-head-st-louis-con-old
#| tbl-cap: St Louis Concentration Old
#| echo: false

(
    st_louis_con_old
    .head()
    .style
)
```

```{python}
#| label: tbl-head-st-louis-unc-old
#| tbl-cap: St Louis Uncertainty Old
#| echo: false

(
    st_louis_unc_old
    .head()
    .style
)
```

```{python}
#| label: tbl-head-st-louis-con
#| tbl-cap: St Louis Concentration
#| echo: false

(
    st_louis_con
    .head()
    .style
)
```

```{python}
#| label: tbl-head-st-louis-unc
#| tbl-cap: St Louis Uncertainty
#| echo: false

(
    st_louis_unc
    .head()
    .style
)

```

```{python}
#| label: tbl-head-st-louis-lon
#| tbl-cap: St Louis Combined
#| echo: false

(
    st_louis_lon
    .head()
    .style
)
```

# Baltimore

```{python}
#| label: fig-baltimore-why-log
#| fig-cap: Distribution

fig, axs = plt.subplots(1, 2)

sns.histplot(x="PM2.5", data=baltimore_con_old, ax=axs[0])
axs[0].set_xlabel("Particulate Matter 2.5")
axs[0].set_title("Raw Data")

sns.histplot(x="pm2.5", data=baltimore_con, ax=axs[1])
axs[1].set_xlabel("Particulate Matter 2.5")
axs[1].set_title("log(x + 1)")

fig.suptitle("Baltimore PM2.5: Raw vs Transformed");
```

```{python}
#| label: tbl-baltimore-extreme-values

(
    baltimore_con_old
    .unpivot(index="Date", variable_name="Species", value_name="Concentration")
    .group_by("Species")
    .agg(
        pl.col("Concentration").mean().alias("mean"),
        pl.col("Concentration").max().alias("max")
    )
    .sort("max", descending=True)
    .head()
    .with_columns(
        (pl.col("max") / pl.col("mean")).alias("max_mean_ratio")
    )
    .style
    .fmt_number(cs.numeric(), decimals=2)
)
```

```{python}
#| label: fig-baltimore-heat-map

fig, ax = plt.subplots()

corr_matrix = (
    baltimore_con
    .select(
        "ammonium_ion",
        "sulfate",
        "organic_carbon",
        "om",
        "pm2.5"
    )
    .to_pandas()
    .corr(numeric_only=True)
    .transpose()
)

sns.heatmap(
    corr_matrix,
    annot=True,
    cmap=sns.cubehelix_palette(start=2, rot=0, dark=.12, light=.95, as_cmap=True),
    ax=ax
)

ax.set_title("Baltimore: Top 5 PM Components Correlation")
ax.invert_yaxis()
```

# Baton Rouge

```{python}
#| label: fig-baton-rouge-why-log
#| fig-cap: Distribution

fig, axs = plt.subplots(1, 2)

sns.histplot(x="Unidentified", data=baton_rouge_con_old, ax=axs[0])
axs[0].set_xlabel("Unidentified")
axs[0].set_title("Raw Data")

sns.histplot(x="unidentified", data=baton_rouge_con, ax=axs[1])
axs[1].set_xlabel("Unidentified")
axs[1].set_title("log(x + 1)");
```

```{python}
#| label: tbl-baton-rouge-extreme-values

(
    baton_rouge_con_old
    .unpivot(index="Date", variable_name="Species", value_name="concentration")
    .group_by("Species")
    .agg(
        pl.col("concentration").mean().alias("mean"),
        pl.col("concentration").max().alias("max")
    )
    .sort("max", descending=True)
    .head()
    .with_columns(
        (pl.col("max") / pl.col("mean")).alias("max_mean_ratio")
    )
    .style
    .fmt_number(cs.numeric(), decimals=2)
)
```

# St. Louis

```{python}
#| label: fig-st-louis--why-log
#| fig-cap: Distribution

fig, axs = plt.subplots(1, 2)

sns.histplot(x="Mass", data=st_louis_con_old, ax=axs[0])
axs[0].set_xlabel("Particulate Matter 2.5")
axs[0].set_title("Raw Data")

sns.histplot(x="pm2.5", data=st_louis_con, ax=axs[1])
axs[1].set_xlabel("Particulate Matter 2.5")
axs[1].set_title("log(x + 1)");
```

```{python}
#| label: tbl-st-louis-extreme-values

(
    st_louis_con_old
    .unpivot(index="Date", variable_name="Species", value_name="concentration")
    .group_by("Species")
    .agg(
        pl.col("concentration").mean().alias("mean"),
        pl.col("concentration").max().alias("max")
    )
    .sort("max", descending=True)
    .head()
    .with_columns(
        (pl.col("max") / pl.col("mean")).alias("max_mean_ratio")
    )
    .style
    .fmt_number(cs.numeric(), decimals=2)
)
```

# Used in Presentation

```{python}
#| label: fig-pairwise-baltimore
#| tbl-cap: Baltimore Pairwise Plot

sns.pairplot(
    baltimore_con
    .select(
        "ammonium_ion",
        "sulfate",
        "organic_carbon",
        "om",
        "pm2.5"
    )
    .to_pandas(),
)

plt.title("Pairwise Plots of Most Correlated Species")


```

```{python}
#| label: tbl-species-baton-rouge
#| tbl-cap: Baton Rouge Chemical Species

 
```

```{python}
#| label: tbl-species-st-louis
#| tbl-cap: St. Louis Chemical Species

 
```

# Links

## Useful Reference for modeling later

<a href="https://cloud.r-project.org/web/packages/pcpr/vignettes/pcp-applied.html" target="_blank" rel="noopener noreferrer">R code example doing Non-Negative Matrix Factorization</a>

<a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html" target="_blank" rel="noopener noreferrer">Python code example doing Non-Negative Matrix Factorization</a>

## References

<a href="https://www.nrcs.usda.gov/sites/default/files/2022-10/4-Source-Apportionment.pdf" target="_blank" rel="noopener noreferrer">Powerpoint also on elc. This is Rizzo</a>